# Functional Conformance Status

**Last Updated:** 2026-02-10

This document tracks the **actual implementation status** of the Responses API, distinguishing between:
- âœ… **Fully Implemented** - Parameter works as expected
- âš ï¸ **Schema Only** - Accepted and echoed, but NOT used in LLM calls
- ğŸ”„ **Mocked** - Simulated behavior for testing
- âŒ **Not Implemented** - Not supported at all

---

## API Conformance Summary

| Metric | Score | Notes |
|--------|-------|-------|
| **OpenAPI Schema Conformance** | 99.5% | OpenAPI spec matches OpenAI |
| **Functional Conformance** | ~85% | Full parameter passthrough, real tool calling, multi-turn |
| **Endpoint Coverage** | 100% | All 41 endpoints schema-complete |

---

## Responses API - Parameter Implementation

### âœ… Fully Implemented (16 parameters)

| Parameter | Status | Implementation |
|-----------|--------|----------------|
| `model` | âœ… | Passed to LLM backend |
| `input` | âœ… | Parsed as string, message array, function_call, or function_call_output items |
| `instructions` | âœ… | Converted to system message |
| `temperature` | âœ… | Passed to LLM via openai-go SDK |
| `max_output_tokens` | âœ… | Passed as `max_completion_tokens` (preferred) with fallback to `max_tokens` |
| `top_p` | âœ… | Passed to LLM via openai-go SDK |
| `frequency_penalty` | âœ… | Passed to LLM via openai-go SDK |
| `presence_penalty` | âœ… | Passed to LLM via openai-go SDK |
| `tools` | âœ… | Function tools converted and passed to LLM; real tool calls returned |
| `tool_choice` | âœ… | Supports "none", "auto", "required", and named function choice |
| `parallel_tool_calls` | âœ… | Passed to LLM via openai-go SDK |
| `previous_response_id` | âœ… | Loads stored conversation history for multi-turn |
| `reasoning` | âœ… | Effort mapped to openai-go SDK `reasoning_effort` |
| `prompt_cache_key` | âœ… | Passed to LLM via openai-go SDK |
| `safety_identifier` | âœ… | Passed to LLM via openai-go SDK |
| `max_tool_calls` | âœ… | Controls agentic loop iteration limit (default 10) |

**Code Location:** `pkg/core/engine/engine.go` (`buildLLMRequest()`) and `pkg/core/api/openai_client.go` (`buildParams()`)

---

### âš ï¸ Schema Only - NOT Passed to LLM (5 parameters)

These are **accepted, validated, and echoed** in the response, but **NOT used** in LLM calls:

| Parameter | Echoed? | Why Not Used |
|-----------|---------|--------------|
| `truncation` | âœ… | No direct chat completions equivalent |
| `top_logprobs` | âœ… | Passed to SDK but logprobs not surfaced in response |
| `service_tier` | âœ… | OpenAI-specific billing, not applicable to all backends |
| `background` | âœ… | Async processing not yet implemented |
| `store` | âœ… | Session storage only, not LLM param |

**Note:** `metadata` and `include` are correctly not passed to LLM (they are gateway-level params).

---

### âœ… Real Tool Calling

Tool calling is fully implemented with an agentic loop:

1. **Function tools** (`type="function"`) are converted to chat completion tool parameters
2. Tools are passed to the LLM via the openai-go SDK
3. When the LLM returns `finish_reason: "tool_calls"`, function_call output items are emitted
4. Function tools are client-side â€” the loop breaks to let the client execute and send results back
5. Clients send results via `function_call_output` items in the input array
6. The agentic loop respects `max_tool_calls` (default 10) and `max_output_tokens` budget

**Streaming tool calls** emit proper SSE events:
- `response.function_call_arguments.delta` â€” argument chunks as they arrive
- `response.function_call_arguments.done` â€” final arguments
- `response.output_item.added` / `response.output_item.done` â€” tool call items

**Code Location:** `pkg/core/engine/engine.go` (agentic loop in `ProcessRequest()` and `ProcessRequestStream()`)

---

### âœ… Multi-Turn Conversations

Multi-turn is fully implemented via `previous_response_id`:

1. When `previous_response_id` is set, the engine loads the stored response
2. Conversation messages from the previous response are reconstructed
3. Previous output items (messages, function_calls, function_call_output) are appended as context
4. Instructions are prepended as a system message (if not already present)
5. Current input is appended
6. All messages are stored with the response for the next turn in the chain

**Code Location:** `pkg/core/engine/engine.go` (`buildConversationMessages()`)

---

### âŒ Not Implemented

| Feature | Status | Notes |
|---------|--------|-------|
| RAG / Vector Store integration | âŒ | Endpoints exist but return empty/stub data |
| File attachments in input | âŒ | Schema accepts but not processed |
| `file_search` / `web_search` tools | âŒ | Only `function` type tools are supported |
| Background/async processing | âŒ | `background` param echoed but not used |

---

## Endpoint Implementation Status

### Responses API (6/6 endpoints)

| Endpoint | Status | Notes |
|----------|--------|-------|
| POST /v1/responses | âœ… | Non-streaming & streaming (24 SSE events) |
| GET /v1/responses | âœ… | List with pagination (after, before, limit, order, model) |
| GET /v1/responses/{id} | âœ… | Retrieve stored response |
| DELETE /v1/responses/{id} | âœ… | Delete response |
| GET /v1/responses/{id}/input_items | âœ… | Retrieve input items |
| POST /responses | âœ… | Alias for /v1/responses (Open Responses spec) |

**Functional Status:**
- Request validation: âœ… OpenAPI schema enforced
- Response format: âœ… 100% spec compliant
- LLM integration: âœ… Full parameter passthrough
- Tool calling: âœ… Real tool calls via agentic loop
- Multi-turn: âœ… Conversation history loaded from previous responses
- Streaming: âœ… Including tool call deltas and incremental persistence

### Conversations API (6/6 endpoints)

| Endpoint | Status | Notes |
|----------|--------|-------|
| POST /v1/conversations | âœ… | Create conversation |
| GET /v1/conversations | âœ… | List with pagination |
| GET /v1/conversations/{id} | âœ… | Get conversation |
| DELETE /v1/conversations/{id} | âœ… | Delete conversation |
| POST /v1/conversations/{id}/items | âœ… | Add conversation items |
| GET /v1/conversations/{id}/items | âœ… | List conversation items |

### Models API (2/2 endpoints)

| Endpoint | Status | Notes |
|----------|--------|-------|
| GET /v1/models | âœ… | Returns available models |
| GET /v1/models/{id} | âœ… | Get specific model details |

### Prompts API (7/7 endpoints) â€” versioned, llama-stack pattern

| Endpoint | Status | Notes |
|----------|--------|-------|
| POST /v1/prompts | âœ… | Create prompt template (version 1) |
| GET /v1/prompts | âœ… | List prompts (default version of each) |
| GET /v1/prompts/{id} | âœ… | Get prompt (default or `?version=N`) |
| PUT /v1/prompts/{id} | âœ… | Update prompt (creates new version; `version` field required) |
| DELETE /v1/prompts/{id} | âœ… | Delete prompt (all versions) |
| GET /v1/prompts/{id}/versions | âœ… | List all versions of a prompt |
| POST /v1/prompts/{id}/default_version | âœ… | Set the default version |

### Files API (5/5 endpoints)

| Endpoint | Status | Notes |
|----------|--------|-------|
| POST /v1/files | âœ… | Upload works (multipart) |
| GET /v1/files | âœ… | List with pagination |
| GET /v1/files/{id} | âœ… | Metadata retrieval works |
| GET /v1/files/{id}/content | âœ… | Download works |
| DELETE /v1/files/{id} | âœ… | Deletion works |

**Limitation:** Files uploaded but not used in responses (no multimodal support yet).

### Vector Stores API (14/14 endpoints)

| Endpoint | Status | Notes |
|----------|--------|-------|
| POST /v1/vector_stores | âœ… | Create works |
| GET /v1/vector_stores | âœ… | List works |
| GET /v1/vector_stores/{id} | âœ… | Get works |
| PUT /v1/vector_stores/{id} | âœ… | Update works |
| DELETE /v1/vector_stores/{id} | âœ… | Delete works |
| POST /v1/vector_stores/{id}/files | âœ… | Add file works |
| GET /v1/vector_stores/{id}/files | âœ… | List files works |
| GET /v1/vector_stores/{id}/files/{file_id} | âœ… | Get file works |
| DELETE /v1/vector_stores/{id}/files/{file_id} | âœ… | Delete file works |
| GET /v1/vector_stores/{id}/files/{file_id}/content | âœ… | Get content works |
| POST /v1/vector_stores/{id}/search | ğŸ”„ | Endpoint works but returns stub data |
| POST /v1/vector_stores/{id}/file_batches | âœ… | Create batch works |
| GET /v1/vector_stores/{id}/file_batches/{batch_id} | âœ… | Get batch works |
| GET /v1/vector_stores/{id}/file_batches/{batch_id}/files | âœ… | List batch files works |
| POST /v1/vector_stores/{id}/file_batches/{batch_id}/cancel | âœ… | Cancel batch works |

**Limitations:**
- Search functionality: âŒ No actual vector embeddings or similarity search
- RAG integration: âŒ Not connected to responses API

---

## Testing Coverage

| Test Type | Status | Coverage |
|-----------|--------|----------|
| **OpenAPI Schema** | âœ… | 99.5% conformant |
| **Smoke Tests** | âœ… | 9 test suites pass |
| **Unit Tests** | âš ï¸ | Limited coverage |
| **Integration Tests** | âš ï¸ | Basic scenarios only |

---

## Known Gaps vs OpenAI

| Feature | OpenAI | This Gateway | Gap |
|---------|--------|--------------|-----|
| Parameter support | ~40 params | 16 functional | Non-LLM params remaining |
| Tool calling | âœ… Real | âœ… Real | âœ… Parity for function tools |
| Multi-turn | âœ… Real | âœ… Real | âœ… Parity |
| RAG/Search | âœ… Real | âŒ Stub | Not implemented |
| Vision | âœ… Real | âŒ None | Not implemented |
| Streaming | âœ… Real | âœ… Real | âœ… Works with tool calls |

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Responses API Request                              â”‚
â”‚ (18+ parameters accepted via OpenAPI schema)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Engine.ProcessRequest()                            â”‚
â”‚ â€¢ Echoes all params to response âœ…                 â”‚
â”‚ â€¢ Builds conversation from previous_response_id âœ… â”‚
â”‚ â€¢ Parses input items (message, function_call,      â”‚
â”‚   function_call_output) âœ…                         â”‚
â”‚ â€¢ Agentic loop with token budget âœ…                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ChatCompletionRequest (full passthrough)           â”‚
â”‚ â€¢ model, messages, temperature, top_p              â”‚
â”‚ â€¢ frequency_penalty, presence_penalty              â”‚
â”‚ â€¢ max_completion_tokens, tools, tool_choice        â”‚
â”‚ â€¢ parallel_tool_calls, reasoning_effort            â”‚
â”‚ â€¢ prompt_cache_key, safety_identifier              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenAI Client (openai-go SDK v1.12.0)              â”‚
â”‚ â€¢ Full parameter passthrough                       â”‚
â”‚ â€¢ Tool call extraction from responses              â”‚
â”‚ â€¢ Tool call delta handling in streaming             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
            [LLM Backend]
```

---

## Version History

- **2026-02-10**: Major functional upgrade
  - Full parameter passthrough (16/18 params functional, up from 5)
  - Real tool calling with agentic loop (removed mock)
  - Multi-turn conversations via previous_response_id
  - Streaming tool call support (delta/done events)
  - Incremental persistence during streaming
  - Input array parsing (message, function_call, function_call_output)

- **2026-02-10**: Updated endpoint coverage
  - Added 3 missing Responses API endpoints (list, delete, input_items)
  - All 41 endpoints now schema-complete (100%)

- **2026-02-09**: Initial functional conformance audit
  - OpenAPI schema: 99.5% âœ…
  - Functional implementation: ~35% âš ï¸
  - Gap identified and documented

---

## See Also

- [CONFORMANCE.md](./CONFORMANCE.md) - Open Responses spec conformance (100%)
- [CONFORMANCE_STATUS.md](./CONFORMANCE_STATUS.md) - OpenAPI conformance vs OpenAI
- [TESTING.md](./TESTING.md) - Testing guide
- [PROJECT_PLAN.md](./PROJECT_PLAN.md) - Implementation roadmap
